{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from six.moves import cPickle\n",
    "import numpy as np\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from scipy import misc\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Loading net skeleton with parameters name and shapes.\n",
    "with open(\"util/net_skeleton.ckpt\", \"rb\") as f:\n",
    "    net_skeleton = cPickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "num_layers    = [2, 2, 3, 3, 3, 1, 1, 1]\n",
    "dilations     = [[1, 1],\n",
    "                 [1, 1],\n",
    "                 [1, 1, 1],\n",
    "                 [1, 1, 1],\n",
    "                 [2, 2, 2],\n",
    "                 [12], \n",
    "                 [1], \n",
    "                 [1]]\n",
    "n_classes = 21\n",
    "ks = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_variable(name, shape):\n",
    "    \"\"\"Create a convolution filter variable of the given name and shape,\n",
    "       and initialise it using Xavier initialisation \n",
    "       (http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf).\n",
    "    \"\"\"\n",
    "    initialiser = tf.contrib.layers.xavier_initializer_conv2d(dtype=tf.float32)\n",
    "    variable = tf.Variable(initialiser(shape=shape), name=name)\n",
    "    tf.summary.histogram(name, variable)\n",
    "    return variable\n",
    "\n",
    "def create_bias_variable(name, shape):\n",
    "    \"\"\"Create a bias variable of the given name and shape,\n",
    "       and initialise it to zero.\n",
    "    \"\"\"\n",
    "    initialiser = tf.constant_initializer(value=0.0, dtype=tf.float32)\n",
    "    variable = tf.Variable(initialiser(shape=shape), name=name)\n",
    "    tf.summary.histogram(name, variable)\n",
    "    return variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def neural_net_image_input(image_shape):\n",
    "        \"\"\"\n",
    "        Return a Tensor for a batch of image input\n",
    "        : image_shape: Shape of the images\n",
    "        : return: Tensor for image input.\n",
    "        \"\"\"\n",
    "        # TODO: Implement Function\n",
    "        return tf.placeholder(tf.float32,shape=(None,image_shape[0],image_shape[1],image_shape[2]),name=\"x\")\n",
    "def neural_net_label_input(image_shape):\n",
    "        \"\"\"\n",
    "        Return a Tensor for a batch of image input\n",
    "        : image_shape: Shape of the images\n",
    "        : return: Tensor for image input.\n",
    "        \"\"\"\n",
    "        # TODO: Implement Function\n",
    "        return tf.placeholder(tf.uint8,shape=(None,image_shape[0],image_shape[1],image_shape[2]),name=\"y\")\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32,name=\"keep_prob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class DeepLabLFOVModel(object):\n",
    "    def __init__(self, weights_path=None):\n",
    "        self.variables = self._create_variables(weights_path)\n",
    "    \n",
    "    def _create_variables(self, weights_path):\n",
    "        var = list()\n",
    "        index = 0\n",
    "        \n",
    "        if weights_path is not None:\n",
    "            with open(weights_path, \"rb\") as f:\n",
    "                weights = cPickle.load(f) # Load pre-trained weights.\n",
    "                for name, shape in net_skeleton:\n",
    "                    var.append(tf.Variable(weights[name],\n",
    "                                           name=name))\n",
    "                del weights\n",
    "        else:\n",
    "            # Initialise all weights randomly with the Xavier scheme,\n",
    "            # and \n",
    "            # all biases to 0's.\n",
    "            for name, shape in net_skeleton:\n",
    "                if \"/w\" in name: # Weight filter.\n",
    "                    w = create_variable(name, list(shape))\n",
    "                    var.append(w)\n",
    "                else:\n",
    "                    b = create_bias_variable(name, list(shape))\n",
    "                    var.append(b)\n",
    "        return var\n",
    "    \n",
    "    def _create_network(self, input_batch, keep_prob):\n",
    "        \n",
    "        current = input_batch\n",
    "        v_idx = 0\n",
    "        for b_idx in range(len(dilations) - 1):\n",
    "            for l_idx, dilation in enumerate(dilations[b_idx]):\n",
    "                w = self.variables[v_idx * 2]\n",
    "                b = self.variables[v_idx * 2 + 1]\n",
    "                if dilation == 1:\n",
    "                    conv = tf.nn.conv2d(current, w, strides=[1, 1, 1, 1], padding='SAME')\n",
    "                else:\n",
    "                    conv = tf.nn.atrous_conv2d(current, w, dilation, padding='SAME')\n",
    "                current = tf.nn.relu(tf.nn.bias_add(conv, b))\n",
    "                v_idx += 1\n",
    "                \n",
    "            if b_idx < 3:\n",
    "                current = tf.nn.max_pool(current, \n",
    "                                         ksize=[1, ks, ks, 1],\n",
    "                                         strides=[1, 2, 2, 1],\n",
    "                                         padding='SAME')\n",
    "            elif b_idx == 3:\n",
    "                current = tf.nn.max_pool(current, \n",
    "                             ksize=[1, ks, ks, 1],\n",
    "                             strides=[1, 1, 1, 1],\n",
    "                             padding='SAME')\n",
    "            elif b_idx == 4:\n",
    "                current = tf.nn.max_pool(current, \n",
    "                                         ksize=[1, ks, ks, 1],\n",
    "                                         strides=[1, 1, 1, 1],\n",
    "                                         padding='SAME')\n",
    "                current = tf.nn.avg_pool(current, \n",
    "                                         ksize=[1, ks, ks, 1],\n",
    "                                         strides=[1, 1, 1, 1],\n",
    "                                         padding='SAME')\n",
    "            elif b_idx <= 6:\n",
    "                current = tf.nn.dropout(current, keep_prob=keep_prob)\n",
    "        \n",
    "        # Classification layer; no ReLU.\n",
    "        w = self.variables[v_idx * 2]\n",
    "        b = self.variables[v_idx * 2 + 1]\n",
    "        conv = tf.nn.conv2d(current, w, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        current = tf.nn.bias_add(conv, b)\n",
    "\n",
    "        return current\n",
    "    \n",
    "    \n",
    "    def preds(self, input_batch):\n",
    "        \"\"\"Create the network and run inference on the input batch.\n",
    "        \n",
    "        Args:\n",
    "          input_batch: batch of pre-processed images.\n",
    "          \n",
    "        Returns:\n",
    "          Argmax over the predictions of the network of the same shape as the input.\n",
    "        \"\"\"\n",
    "        \n",
    "        raw_output = self._create_network(tf.cast(input_batch, tf.float32),  keep_prob=tf.constant(1.0))\n",
    "        #print(raw_output.shape)\n",
    "        raw_output = tf.image.resize_bilinear(raw_output, tf.shape(input_batch)[1:3,])\n",
    "        #print(raw_output.shape)\n",
    "        raw_output = tf.argmax(raw_output, dimension=3)\n",
    "        #print(raw_output.shape)\n",
    "        raw_output = tf.expand_dims(raw_output, dim=3) # Create 4D-tensor.\n",
    "        #print(raw_output.shape)\n",
    "        return tf.cast(raw_output, tf.uint8)\n",
    "    \n",
    "    def loss(self, img_batch, label_batch,keep_prob_input):\n",
    "        \"\"\"Create the network, run inference on the input batch and compute loss.\n",
    "        \n",
    "        Args:\n",
    "          input_batch: batch of pre-processed images.\n",
    "          \n",
    "        Returns:\n",
    "          Pixel-wise softmax loss.\n",
    "        \"\"\"\n",
    "        raw_output = self._create_network(tf.cast(img_batch, tf.float32), keep_prob_input)\n",
    "        #print(raw_output.shape)\n",
    "        \n",
    "        \n",
    "        lbels= tf.image.resize_nearest_neighbor(label_batch,tf.stack(raw_output.get_shape()[1:3]))\n",
    "        prediction = tf.reshape(raw_output, [-1, n_classes])\n",
    "        lbels = tf.squeeze(lbels, squeeze_dims=[3]) # Reducing the channel dimension.\n",
    "        lbels = tf.one_hot(lbels, depth=21)\n",
    "        gt = tf.reshape(lbels, [-1, n_classes])\n",
    "        #print(label_batch.shape)\n",
    "        # Pixel-wise softmax loss.\n",
    "        loss = tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=gt)\n",
    "        reduced_loss = tf.reduce_mean(loss)\n",
    "        return reduced_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def prepare_label(label_batch):\n",
    "        colormap = {(0,0,0):0, (128,0,0):1, (0,128,0):2, (128,128,0):3, (0,0,128):4, (128,0,128):5, (0,128,128):6, (128,128,128):7, (64,0,0):8, (192,0,0):9, (64,128,0):10, (192,128,0):11, (64,0,128):12, (192,0,128):13, \n",
    "            (64,128,128):14, (192,128,128):15, (0,64,0):16, (128,64,0):17, (0,192,0):18, (128,192,0):19, (0,64,128):20}                                            \n",
    "        gndTruth = np.zeros((label_batch.shape[0],label_batch[0].shape[0],label_batch[0].shape[1],21), dtype=np.int)\n",
    "        for i in range(label_batch.shape[0]):\n",
    "            for j in range(label_batch[0].shape[0]):\n",
    "                for k in range(label_batch[0].shape[1]):   \n",
    "                    if(colormap.get(tuple(label_batch[i][j,k]))):\n",
    "                        gndTruth[i,j,k,colormap.get(tuple(label_batch[i][j,k]))] = 1\n",
    "                    else:\n",
    "                        gndTruth[i,j,k,0] = 1\n",
    "        return gndTruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Colour map.\n",
    "label_colours = [(0,0,0)\n",
    "                # 0=background\n",
    "                ,(128,0,0),(0,128,0),(128,128,0),(0,0,128),(128,0,128)\n",
    "                # 1=aeroplane, 2=bicycle, 3=bird, 4=boat, 5=bottle\n",
    "                ,(0,128,128),(128,128,128),(64,0,0),(192,0,0),(64,128,0)\n",
    "                # 6=bus, 7=car, 8=cat, 9=chair, 10=cow\n",
    "                ,(192,128,0),(64,0,128),(192,0,128),(64,128,128),(192,128,128)\n",
    "                # 11=diningtable, 12=dog, 13=horse, 14=motorbike, 15=person\n",
    "                ,(0,64,0),(128,64,0),(0,192,0),(128,192,0),(0,64,128)]\n",
    "                # 16=potted plant, 17=sheep, 18=sofa, 19=train, 20=tv/monitor\n",
    "    \n",
    "def decode_labels(mask):\n",
    "    \"\"\"Decode batch of segmentation masks.\n",
    "    \n",
    "    Args:\n",
    "      label_batch: result of inference after taking argmax.\n",
    "    \n",
    "    Returns:\n",
    "      An batch of RGB images of the same size\n",
    "    \"\"\"\n",
    "    img = Image.new('RGB', (len(mask[0]), len(mask)))\n",
    "    pixels = img.load()\n",
    "    for j_, j in enumerate(mask):\n",
    "        for k_, k in enumerate(j):\n",
    "            if k < 21:\n",
    "                pixels[k_,j_] = label_colours[k]\n",
    "    return np.array(img)\n",
    "def encode_labels(label_batch):\n",
    "        colormap = {(0,0,0):0, (128,0,0):1, (0,128,0):2, (128,128,0):3, (0,0,128):4, (128,0,128):5, (0,128,128):6, (128,128,128):7, (64,0,0):8, (192,0,0):9, (64,128,0):10, (192,128,0):11, (64,0,128):12, (192,0,128):13, \n",
    "            (64,128,128):14, (192,128,128):15, (0,64,0):16, (128,64,0):17, (0,192,0):18, (128,192,0):19, (0,64,128):20}                                            \n",
    "        gndTruth = np.zeros((label_batch.shape[0],label_batch[0].shape[0],label_batch[0].shape[1],1), dtype=np.int)\n",
    "        for i in range(gndTruth.shape[0]):\n",
    "            for j in range(gndTruth.shape[1]):\n",
    "                for k in range(gndTruth.shape[2]):   \n",
    "                    if(colormap.get(tuple(label_batch[i][j,k]))):\n",
    "                        gndTruth[i,j,k]=colormap.get(tuple(label_batch[i][j,k]))\n",
    "                    else:\n",
    "                        gndTruth[i,j,k] = 0\n",
    "        return gndTruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def load_preprocess_training_batch(batch_id):\n",
    "    \"\"\"\n",
    "    Load the Preprocessed Training data and return them in batches of <batch_size> or less\n",
    "    \"\"\"\n",
    "    path = 'VOCdevkit/VOC2012/'\n",
    "    x='2007_000032'\n",
    "    features = np.array([misc.imread(path+\"JPEGImages/\"+x+\".jpg\")])\n",
    "    labels = np.array([misc.imread(path+\"SegmentationClass/\"+x+\".png\")])\n",
    "    # Return the training data in batches of size <batch_size> or less\n",
    "    return features, labels\n",
    "# def load_preprocess_training_batch(batch_id):\n",
    "#     \"\"\"\n",
    "#     Load the Preprocessed Training data and return them in batches of <batch_size> or less\n",
    "#     \"\"\"\n",
    "#     filename = 'data/pre_processed_batch_' + str(batch_id) + '.p'\n",
    "#     loaded_features, loaded_labels = cPickle.load(open(filename, mode='rb'))\n",
    "#     # Return the training data in batches of size <batch_size> or less\n",
    "#     return loaded_features, loaded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-41-1d71c194e939>:89: calling argmax (from tensorflow.python.ops.math_ops) with dimension is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n"
     ]
    }
   ],
   "source": [
    "save_model_path = \"experiment\"\n",
    "image_save_path = \"images/\"\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((500, 500, 3))\n",
    "y = neural_net_label_input((500, 500, 1))\n",
    "# x = tf.image.resize_image_with_crop_or_pad(x,320,320)\n",
    "# y = tf.image.resize_image_with_crop_or_pad(y,320,320)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "keep_prob_pred=tf.placeholder(tf.float32,name=\"keep_prob_pred\")\n",
    "net = DeepLabLFOVModel()\n",
    "cost = net.loss(x, y,keep_prob)\n",
    "cost_summary=tf.summary.scalar(\"loss\",cost)\n",
    "optim = tf.train.AdamOptimizer(learning_rate=0.01).minimize(cost)\n",
    "saver = tf.train.Saver(max_to_keep=40);  \n",
    "pred = net.preds(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'x:0' shape=(?, 500, 500, 3) dtype=float32>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "merged = tf.summary.merge_all()\n",
    "file_writer = tf.summary.FileWriter('logs/', sess.graph)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch_i=0\n",
    "epoch=0\n",
    "keep_probability = 0.75\n",
    "IMG_MEAN = np.array((116.66876762,104.00698793,122.67891434), dtype=np.float32)\n",
    "start_time = time.time()\n",
    "batch_features, batch_labels = load_preprocess_training_batch(batch_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "img_tensor = tf.image.resize_image_with_crop_or_pad(batch_features, 500, 500)\n",
    "#batch_input_resized = batch_input_resized - IMG_MEAN\n",
    "batch_labels_tensor = tf.image.resize_image_with_crop_or_pad(batch_labels, 500, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "img,labels = sess.run([img_tensor,batch_labels_tensor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "img[:,:,:] = img[:,:,:] - IMG_MEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch_labels_array_new = encode_labels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 500, 500, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 281, 500, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(0,1):\n",
    "    loss_value,op,_=sess.run([cost,pred,optim],feed_dict={x:img,y:batch_labels_array_new,keep_prob:keep_probability,keep_prob_pred:1.0})\n",
    "    #file_writer.add_summary(summary_variable, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "raw_output = net._create_network(x, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "res1=sess.run(raw_output,feed_dict={x:img,keep_prob:keep_probability})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(63), Dimension(63), Dimension(21)])"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_features.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2253219.2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "label_op= tf.image.resize_nearest_neighbor(y,tf.stack(raw_output.get_shape()[1:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lbl1 = sess.run(label_op,feed_dict={y:batch_labels_array_new})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 63, 63, 1)"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbl1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "prediction = tf.reshape(raw_output, [-1, n_classes])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "labels = tf.squeeze(label_op, squeeze_dims=[3]) # Reducing the channel dimension.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lbl2 = sess.run(labels,feed_dict={y:batch_labels_array_new})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for i in range(63):\n",
    "    for j in range(63):\n",
    "        if(lbl2[0,i,j]!=0):\n",
    "            print(lbl2[0,i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "labels = tf.one_hot(labels, depth=21)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lbl3 = sess.run(labels,feed_dict={y:batch_labels_array_new})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 63, 63, 21)"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbl3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 1.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 1.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 1.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        ..., \n",
       "        [[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 1.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 1.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 1.,  0.,  0., ...,  0.,  0.,  0.]]]], dtype=float32)"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbl3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 24 1 1.0\n",
      "26 24 1 1.0\n",
      "27 18 1 1.0\n",
      "27 19 1 1.0\n",
      "27 20 1 1.0\n",
      "27 21 1 1.0\n",
      "27 22 1 1.0\n",
      "27 23 1 1.0\n",
      "27 24 1 1.0\n",
      "28 18 1 1.0\n",
      "28 21 1 1.0\n",
      "28 27 1 1.0\n",
      "28 28 1 1.0\n",
      "28 29 1 1.0\n",
      "28 30 1 1.0\n",
      "28 31 1 1.0\n",
      "28 33 1 1.0\n",
      "28 34 1 1.0\n",
      "29 26 1 1.0\n",
      "29 27 1 1.0\n",
      "29 28 1 1.0\n",
      "29 29 1 1.0\n",
      "29 30 1 1.0\n",
      "29 31 1 1.0\n",
      "29 32 1 1.0\n",
      "29 33 1 1.0\n",
      "29 34 1 1.0\n",
      "30 14 1 1.0\n",
      "30 15 1 1.0\n",
      "30 16 1 1.0\n",
      "30 17 1 1.0\n",
      "30 18 1 1.0\n",
      "30 19 1 1.0\n",
      "30 20 1 1.0\n",
      "30 21 1 1.0\n",
      "30 26 1 1.0\n",
      "30 27 1 1.0\n",
      "30 28 1 1.0\n",
      "30 29 1 1.0\n",
      "30 30 1 1.0\n",
      "30 31 1 1.0\n",
      "30 43 1 1.0\n",
      "30 44 1 1.0\n",
      "30 45 1 1.0\n",
      "30 46 1 1.0\n",
      "30 47 1 1.0\n",
      "31 26 1 1.0\n",
      "31 27 1 1.0\n",
      "31 28 1 1.0\n",
      "31 29 1 1.0\n",
      "31 30 1 1.0\n",
      "31 32 1 1.0\n",
      "31 33 1 1.0\n",
      "31 34 1 1.0\n",
      "31 35 1 1.0\n",
      "32 26 1 1.0\n",
      "32 27 1 1.0\n",
      "32 28 1 1.0\n",
      "32 29 1 1.0\n",
      "32 30 1 1.0\n",
      "33 26 1 1.0\n",
      "33 27 1 1.0\n",
      "33 28 1 1.0\n",
      "33 29 1 1.0\n",
      "33 30 1 1.0\n",
      "33 33 1 1.0\n",
      "34 26 1 1.0\n",
      "34 27 1 1.0\n",
      "34 28 1 1.0\n",
      "34 29 1 1.0\n",
      "35 27 1 1.0\n",
      "35 28 1 1.0\n",
      "36 27 1 1.0\n",
      "36 28 1 1.0\n",
      "37 26 15 1.0\n",
      "38 4 15 1.0\n",
      "38 25 15 1.0\n",
      "38 26 15 1.0\n",
      "39 4 15 1.0\n",
      "39 25 15 1.0\n",
      "39 26 15 1.0\n",
      "40 4 15 1.0\n",
      "40 5 15 1.0\n",
      "40 25 15 1.0\n",
      "40 26 15 1.0\n",
      "41 25 15 1.0\n",
      "42 25 15 1.0\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for i in range(63):\n",
    "    for j in range(63):\n",
    "        for k in range(1,21):\n",
    "            if(lbl3[0,i,j,k]!=0):\n",
    "                print(i,j,k, lbl3[0,i,j,k])\n",
    "                count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "gt = tf.reshape(labels, [-1, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lbl2 = sess.run(gt,feed_dict={y:batch_labels_array_new})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "loss = tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.32830977,  2.91328859,  2.82289863, ...,  3.4458065 ,\n",
       "        3.20261836,  3.0960083 ], dtype=float32)"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(loss,feed_dict={x:img,keep_prob:keep_probability,y:batch_labels_array_new})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "reduced_loss = tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.2123799"
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(reduced_loss,feed_dict={x:img,keep_prob:keep_probability,y:batch_labels_array_new})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "opt = sess.run(pred,feed_dict={x:img,keep_prob:keep_probability,y:batch_labels_array_new})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[19],\n",
       "         [19],\n",
       "         [19],\n",
       "         ..., \n",
       "         [19],\n",
       "         [19],\n",
       "         [19]],\n",
       "\n",
       "        [[19],\n",
       "         [19],\n",
       "         [19],\n",
       "         ..., \n",
       "         [19],\n",
       "         [19],\n",
       "         [19]],\n",
       "\n",
       "        [[19],\n",
       "         [19],\n",
       "         [19],\n",
       "         ..., \n",
       "         [19],\n",
       "         [19],\n",
       "         [19]],\n",
       "\n",
       "        ..., \n",
       "        [[18],\n",
       "         [18],\n",
       "         [18],\n",
       "         ..., \n",
       "         [13],\n",
       "         [13],\n",
       "         [13]],\n",
       "\n",
       "        [[18],\n",
       "         [18],\n",
       "         [18],\n",
       "         ..., \n",
       "         [13],\n",
       "         [13],\n",
       "         [13]],\n",
       "\n",
       "        [[18],\n",
       "         [18],\n",
       "         [18],\n",
       "         ..., \n",
       "         [13],\n",
       "         [13],\n",
       "         [13]]]], dtype=uint8)"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11f9d6e48>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(decode_labels(op[0,:,:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQsAAAD8CAYAAABgtYFHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nN2b+k9fwtAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12b2e3208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lbls = decode_labels(op[0,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x117d3d5f8>"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQsAAAD8CAYAAABgtYFHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npBbDQlKLYSGp5X8BvIuo5bB99wsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12776d8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
