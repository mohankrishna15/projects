{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/tensorflow/venv/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/root/tensorflow/venv/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import pickle\n",
    "from scipy import misc\n",
    "import glob\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_sz = 500    # height and width to which all images will be resized to\n",
    "batch_size=16  # dataset will be divided into batches of this size\n",
    "\n",
    "#CELEBA dataset has this file , which should be used to divide the dataset into \n",
    "#training - 0, \n",
    "#validation -1 \n",
    "#testing - 2 \n",
    "\n",
    "evalData = pd.read_csv('evalpartition.txt',sep=\" \",header=None,skipinitialspace=True,names=['image_name','dataset_type'])\n",
    "evalData.set_index('dataset_type',inplace=True)\n",
    "trainData = evalData.loc[0].reset_index()['image_name']\n",
    "valData = evalData.loc[1].reset_index()['image_name']\n",
    "testData = evalData.loc[2].reset_index()['image_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to account to different lightning conditions, this mean RGB is subtracted from all the images\n",
    "IMG_MEAN = np.array((116.66876762,104.00698793,122.67891434), dtype=np.float32)  \n",
    "\n",
    "# Bounding boxes of the faces in dataset are loaded into bbdata\n",
    "bbdata = pd.read_csv('list_bbox_celeba.txt',sep=\" \",header=0,skiprows=1,skipinitialspace=True)\n",
    "bbdata.set_index('image_id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We resize a given image to a standard size, subtract mean from it. Calculate a corresponding output portrait image using bounding box data\n",
    "def preprocess_data(sess,data,boundbox):\n",
    "    b=np.zeros([data.shape[0],data.shape[1],1],dtype=int)\n",
    "    for i in range(0,data.shape[0]):\n",
    "        for j in range(0,data.shape[1]):\n",
    "            if((j>boundbox.x_1) and (j<(boundbox.x_1+boundbox.width)) and (i>boundbox.y_1) and (i<(boundbox.y_1+boundbox.height))):\n",
    "                b[i,j,0] = 15 \n",
    "    img_tensor = tf.image.resize_image_with_crop_or_pad(data, im_sz, im_sz)\n",
    "    labels_tensor = tf.image.resize_image_with_crop_or_pad(b, im_sz, im_sz)\n",
    "            \n",
    "    img,lbls = sess.run([img_tensor,labels_tensor])\n",
    "    img[:,:,:] = img[:,:,:] - IMG_MEAN\n",
    "    return img,lbls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess images and store each batch of images in a file, do the same for training, validation and testing datasets\n",
    "sess = tf.Session()\n",
    "total_features = np.zeros((batch_size,im_sz,im_sz,3))\n",
    "total_output = np.zeros((batch_size,im_sz,im_sz,1))\n",
    "\n",
    "total_features_val = np.zeros((batch_size,im_sz,im_sz,3))\n",
    "total_output_val = np.zeros((batch_size,im_sz,im_sz,3))\n",
    "\n",
    "num_train_batches = int(len(trainData)/batch_size)\n",
    "num_val_batches = int(len(valData)/batch_size)\n",
    "num_test_batches = int(len(yesyData)/batch_size)\n",
    "\n",
    "for i in range(0,num_train_batches+1):\n",
    "    for j in range(0,batch_size):\n",
    "        imgName = trainData[int(i*batch_size)+j]\n",
    "        inputimg = misc.imread(\"data/\"+imgName)\n",
    "        bb=bbdata.loc[imgName]\n",
    "        total_features[j],total_output[j] = preprocess_data(sess,inputimg,bb)\n",
    "        print(\"val \"+str(i)+\" \"+ str(j))\n",
    "    pickle.dump((total_features, total_output), open(\"preprocessed_data/train_data/pre_processed_batch_\"+str(i)+\".p\", 'wb'))\n",
    "    \n",
    "    \n",
    "for i in range(0,num_val_batches+1):\n",
    "    for j in range(0,batch_size):\n",
    "        imgName = valData[int(i*batch_size)+j]\n",
    "        inputimg = misc.imread(\"data/\"+imgName)\n",
    "        bb=bbdata.loc[imgName]\n",
    "        total_features[j],total_output[j] = preprocess_data(sess,inputimg,bb)\n",
    "        print(\"val \"+str(i)+\" \"+ str(j))\n",
    "    pickle.dump((total_features, total_output), open(\"preprocessed_data/val_data/pre_processed_batch_\"+str(i)+\".p\", 'wb'))\n",
    "    \n",
    "for i in range(0,num_test_batches+1):\n",
    "    for j in range(0,batch_size):\n",
    "        imgName = testData[int(i*batch_size)+j]\n",
    "        inputimg = misc.imread(\"data/\"+imgName)\n",
    "        bb=bbdata.loc[imgName]\n",
    "        total_features[j],total_output[j] = preprocess_data(sess,inputimg,bb)\n",
    "        print(\"test \"+str(i)+\" \"+ str(j))\n",
    "    pickle.dump((total_features, total_output), open(\"preprocessed_data/test_data/pre_processed_batch_\"+str(i)+\".p\", 'wb'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
