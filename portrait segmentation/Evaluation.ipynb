{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from six.moves import cPickle\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from model import *   # This has the model(neural network) we will be using for this problem\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_net_image_input(image_shape):\n",
    "        \"\"\"\n",
    "        Return a Tensor for a batch of image input\n",
    "        : image_shape: Shape of the images\n",
    "        : return: Tensor for image input.\n",
    "        \"\"\"\n",
    "        return tf.placeholder(tf.float32,shape=(None,image_shape[0],image_shape[1],image_shape[2]),name=\"x\")\n",
    "def neural_net_label_input(image_shape):\n",
    "        \"\"\"\n",
    "        Return a Tensor for a batch of image input\n",
    "        : image_shape: Shape of the images\n",
    "        : return: Tensor for image input.\n",
    "        \"\"\"\n",
    "        return tf.placeholder(tf.uint8,shape=(None,image_shape[0],image_shape[1],image_shape[2]),name=\"y\")\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    return tf.placeholder(tf.float32,name=\"keep_prob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are using a model trained on pascal voc dataset, which has the following categories defined and finetuning the model for our purposes\n",
    "label_colours = [(0,0,0)\n",
    "                # 0=background\n",
    "                ,(128,0,0),(0,128,0),(128,128,0),(0,0,128),(128,0,128)\n",
    "                # 1=aeroplane, 2=bicycle, 3=bird, 4=boat, 5=bottle\n",
    "                ,(0,128,128),(128,128,128),(64,0,0),(192,0,0),(64,128,0)\n",
    "                # 6=bus, 7=car, 8=cat, 9=chair, 10=cow\n",
    "                ,(192,128,0),(64,0,128),(192,0,128),(64,128,128),(192,128,128)\n",
    "                # 11=diningtable, 12=dog, 13=horse, 14=motorbike, 15=person\n",
    "                ,(0,64,0),(128,64,0),(0,192,0),(128,192,0),(0,64,128)]\n",
    "                # 16=potted plant, 17=sheep, 18=sofa, 19=train, 20=tv/monitor\n",
    "    \n",
    "def decode_labels(mask):\n",
    "    \"\"\"Decode batch of segmentation masks.\n",
    "    \n",
    "    Args:\n",
    "      label_batch: result of inference after taking argmax.\n",
    "    \n",
    "    Returns:\n",
    "      An batch of RGB images of the same size\n",
    "    \"\"\"\n",
    "    imgrgb = Image.new('RGB', (len(mask[0]), len(mask)))\n",
    "    pixels = imgrgb.load()\n",
    "    for j_, j in enumerate(mask):\n",
    "        for k_, k in enumerate(j):\n",
    "            if k < 21:\n",
    "                pixels[k_,j_] = label_colours[k]\n",
    "    return np.array(imgrgb)\n",
    "def encode_labels(label_batch):\n",
    "        colormap = {(0,0,0):0, (128,0,0):1, (0,128,0):2, (128,128,0):3, (0,0,128):4, (128,0,128):5, (0,128,128):6, (128,128,128):7, (64,0,0):8, (192,0,0):9, (64,128,0):10, (192,128,0):11, (64,0,128):12, (192,0,128):13, \n",
    "            (64,128,128):14, (192,128,128):15, (0,64,0):16, (128,64,0):17, (0,192,0):18, (128,192,0):19, (0,64,128):20}                                            \n",
    "        gndTruth = np.zeros((label_batch.shape[0],label_batch[0].shape[0],label_batch[0].shape[1],1), dtype=np.int)\n",
    "        for i in range(gndTruth.shape[0]):\n",
    "            for j in range(gndTruth.shape[1]):\n",
    "                for k in range(gndTruth.shape[2]):   \n",
    "                    if(colormap.get(tuple(label_batch[i][j,k]))):\n",
    "                        gndTruth[i,j,k]=colormap.get(tuple(label_batch[i][j,k]))\n",
    "                    else:\n",
    "                        gndTruth[i,j,k] = 0\n",
    "        return gndTruth\n",
    "def load_preprocess_val_batch(batch_id):\n",
    "    \"\"\"\n",
    "    Load the Preprocessed Training data and return them in batches of <batch_size> or less\n",
    "    \"\"\"\n",
    "    with tf.name_scope(\"create_inputs\"):\n",
    "        filename = 'preprocessed_data/val_data/pre_processed_batch_' + str(batch_id) + '.p'\n",
    "        loaded_features, loaded_labels = cPickle.load(open(filename, mode='rb'))\n",
    "        return loaded_features.astype(np.int64), loaded_labels.astype(np.int64)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CELEBA dataset has this file , which should be used to divide the dataset into \n",
    "#training - 0, \n",
    "#validation -1 \n",
    "#testing - 2 \n",
    "\n",
    "evalData = pd.read_csv('evalpartition.txt',sep=\" \",header=None,skipinitialspace=True,names=['image_name','dataset_type'])\n",
    "evalData.set_index('dataset_type',inplace=True)\n",
    "valData = evalData.loc[1].reset_index()['image_name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_sz = 500    # height and width to which all images will be resized to\n",
    "batch_size=16  # dataset will be divided into batches of this size\n",
    "num_val_batches = int(len(valData)/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/model.ckpt\n",
      "miou: 0.97597533\n",
      "miou: 0.94823194\n",
      "miou: 0.93308693\n",
      "miou: 0.9395124\n",
      "miou: 0.9343871\n",
      "miou: 0.9299934\n",
      "miou: 0.6536574\n",
      "miou: 0.6759488\n",
      "miou: 0.7151912\n",
      "miou: 0.72467136\n",
      "miou: 0.73428655\n",
      "miou: 0.75641644\n",
      "miou: 0.7659766\n",
      "miou: 0.775983\n",
      "miou: 0.7815697\n",
      "miou: 0.74854285\n",
      "batch: 5\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# for validation only CPU can be used\n",
    "config = tf.ConfigProto(\n",
    "        device_count = {'GPU': 0}\n",
    "    )\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "net = SegmentationModel(None)\n",
    "\n",
    "imgold = neural_net_image_input((im_sz, im_sz, 3))\n",
    "x = neural_net_image_input((im_sz, im_sz, 3))\n",
    "y = neural_net_label_input((im_sz, im_sz, 1))\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "pred = net.preds(x)\n",
    "predconv = tf.to_int32(pred, name='ToInt32')\n",
    "yconv = tf.to_int32(y, name='ToInt32') \n",
    "\n",
    "#mean IOU (Intersection over union) is a metric used for the task of semantic segmentation (here portrait segmentation)\n",
    "mIoU, update_op = tf.contrib.metrics.streaming_mean_iou(predconv,yconv, num_classes=21)\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "init = tf.initialize_all_variables()    \n",
    "sess.run(init)\n",
    "sess.run(tf.initialize_local_variables())\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, \"model/model.ckpt\")\n",
    "test_input=np.zeros([1,im_sz,im_sz,3],dtype=np.int)\n",
    "lbl_img = np.zeros([1,im_sz,im_sz,1],dtype=np.int)\n",
    "\n",
    "num_val_batches=1 # printing data for one batch ( for example)\n",
    "for batch_i in range(num_val_batches):\n",
    "    batch_i=5   # printing data for one batch ( for example)\n",
    "    batch_features, batch_labels = load_preprocess_val_batch(batch_i)\n",
    "    for img_i in range(batch_size):\n",
    "        test_input[0,:,:,:] = batch_features[img_i,:,:,:]\n",
    "        lbl_img[0,:,:,0] = batch_labels[img_i,:,:,0]\n",
    "        pred_value,up = sess.run([pred,update_op],feed_dict={x:test_input,y:lbl_img})\n",
    "        print('miou: '+ str(mIoU.eval(session=sess)))\n",
    "print('batch: '+ str(batch_i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
