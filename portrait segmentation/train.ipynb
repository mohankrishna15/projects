{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from six.moves import cPickle\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from model import *   # This has the model(neural network) we will be using for this problem\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_net_image_input(image_shape):\n",
    "        \"\"\"\n",
    "        Return a Tensor for a batch of image input\n",
    "        : image_shape: Shape of the images\n",
    "        : return: Tensor for image input.\n",
    "        \"\"\"\n",
    "        return tf.placeholder(tf.float32,shape=(None,image_shape[0],image_shape[1],image_shape[2]),name=\"x\")\n",
    "def neural_net_label_input(image_shape):\n",
    "        \"\"\"\n",
    "        Return a Tensor for a batch of image input\n",
    "        : image_shape: Shape of the images\n",
    "        : return: Tensor for image input.\n",
    "        \"\"\"\n",
    "        return tf.placeholder(tf.uint8,shape=(None,image_shape[0],image_shape[1],image_shape[2]),name=\"y\")\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    return tf.placeholder(tf.float32,name=\"keep_prob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are using a model trained on pascal voc dataset, which has the following categories defined and finetuning the model for our purposes\n",
    "label_colours = [(0,0,0)\n",
    "                # 0=background\n",
    "                ,(128,0,0),(0,128,0),(128,128,0),(0,0,128),(128,0,128)\n",
    "                # 1=aeroplane, 2=bicycle, 3=bird, 4=boat, 5=bottle\n",
    "                ,(0,128,128),(128,128,128),(64,0,0),(192,0,0),(64,128,0)\n",
    "                # 6=bus, 7=car, 8=cat, 9=chair, 10=cow\n",
    "                ,(192,128,0),(64,0,128),(192,0,128),(64,128,128),(192,128,128)\n",
    "                # 11=diningtable, 12=dog, 13=horse, 14=motorbike, 15=person\n",
    "                ,(0,64,0),(128,64,0),(0,192,0),(128,192,0),(0,64,128)]\n",
    "                # 16=potted plant, 17=sheep, 18=sofa, 19=train, 20=tv/monitor\n",
    "    \n",
    "def decode_labels(mask):\n",
    "    \"\"\"Decode batch of segmentation masks.\n",
    "    \n",
    "    Args:\n",
    "      label_batch: result of inference after taking argmax.\n",
    "    \n",
    "    Returns:\n",
    "      An batch of RGB images of the same size\n",
    "    \"\"\"\n",
    "    imgrgb = Image.new('RGB', (len(mask[0]), len(mask)))\n",
    "    pixels = imgrgb.load()\n",
    "    for j_, j in enumerate(mask):\n",
    "        for k_, k in enumerate(j):\n",
    "            if k < 21:\n",
    "                pixels[k_,j_] = label_colours[k]\n",
    "    return np.array(imgrgb)\n",
    "def encode_labels(label_batch):\n",
    "        colormap = {(0,0,0):0, (128,0,0):1, (0,128,0):2, (128,128,0):3, (0,0,128):4, (128,0,128):5, (0,128,128):6, (128,128,128):7, (64,0,0):8, (192,0,0):9, (64,128,0):10, (192,128,0):11, (64,0,128):12, (192,0,128):13, \n",
    "            (64,128,128):14, (192,128,128):15, (0,64,0):16, (128,64,0):17, (0,192,0):18, (128,192,0):19, (0,64,128):20}                                            \n",
    "        gndTruth = np.zeros((label_batch.shape[0],label_batch[0].shape[0],label_batch[0].shape[1],1), dtype=np.int)\n",
    "        for i in range(gndTruth.shape[0]):\n",
    "            for j in range(gndTruth.shape[1]):\n",
    "                for k in range(gndTruth.shape[2]):   \n",
    "                    if(colormap.get(tuple(label_batch[i][j,k]))):\n",
    "                        gndTruth[i,j,k]=colormap.get(tuple(label_batch[i][j,k]))\n",
    "                    else:\n",
    "                        gndTruth[i,j,k] = 0\n",
    "        return gndTruth\n",
    "def load_preprocess_training_batch(batch_id):\n",
    "    \"\"\"\n",
    "    Load the Preprocessed Training data and return them in batches of <batch_size> or less\n",
    "    \"\"\"\n",
    "    with tf.name_scope(\"create_inputs\"):\n",
    "        filename = 'preprocessed_data/train_data/pre_processed_batch_' + str(batch_id) + '.p'\n",
    "        loaded_features, loaded_labels = cPickle.load(open(filename, mode='rb'))\n",
    "        return loaded_features.astype(np.int64), loaded_labels.astype(np.int64)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CELEBA dataset has this file , which should be used to divide the dataset into \n",
    "#training - 0, \n",
    "#validation -1 \n",
    "#testing - 2 \n",
    "\n",
    "evalData = pd.read_csv('evalpartition.txt',sep=\" \",header=None,skipinitialspace=True,names=['image_name','dataset_type'])\n",
    "evalData.set_index('dataset_type',inplace=True)\n",
    "trainData = evalData.loc[0].reset_index()['image_name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50  # number of iterations\n",
    "keep_probability = 0.75  # means 25% is dropout\n",
    "save_model_path = \"./finalModel\"   # used to save model after each epoch\n",
    "image_save_path = \"images/\"\n",
    "\n",
    "im_sz = 500    # height and width to which all images will be resized to\n",
    "batch_size=16  # dataset will be divided into batches of this size\n",
    "num_train_batches = int(len(trainData)/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'neural_net_image_input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-24b9c7e2e760>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneural_net_image_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneural_net_label_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mkeep_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneural_net_keep_prob_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'neural_net_image_input' is not defined"
     ]
    }
   ],
   "source": [
    "# Inputs\n",
    "x = neural_net_image_input((500, 500, 3))\n",
    "y = neural_net_label_input((500, 500, 1))\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# load model structure with loss and error functons defined from model.py\n",
    "net = SegmentationModel(None)\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=40)\n",
    "\n",
    "# load model pretrained on PASCAL VOC augmented dataset \n",
    "def load_pretrained_model(sess):\n",
    "    if not tf.train.checkpoint_exists(\"model/\"):   # path to save checkpoints\n",
    "        saver.restore(sess, \"model/model.ckpt.data-00000-of-00001\")\n",
    "        print(\"initialised\")\n",
    "        \n",
    "\n",
    "cost = net.loss(x, y,keep_prob)\n",
    "cost_summary=tf.summary.scalar(\"loss\",cost)\n",
    "optim = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)\n",
    " \n",
    "pred = net.preds(x)\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "sv = tf.train.Supervisor(logdir=\"model\", init_fn=load_pretrained_model, summary_op=None)\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "with sv.managed_session(config=config) as sess:\n",
    "    for epoch in range(epochs):\n",
    "        for batch_i  in range(num_train_batches):\n",
    "            if sv.should_stop():\n",
    "                break\n",
    "            start_time = time.time()\n",
    "            batch_features, batch_labels = load_preprocess_training_batch(batch_i)\n",
    "            loss_value,_=sess.run([cost,optim],feed_dict={x:batch_features,y:batch_labels,keep_prob:keep_probability})\n",
    "            duration = time.time() - start_time\n",
    "            print('step {:d}, batch {:d} \\t loss = {:.3f}, ({:.3f} sec/step)'.format(epoch, batch_i, loss_value, duration)) \n",
    "        saver.save(sess, save_model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
